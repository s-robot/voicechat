import asyncio
import random
import threading
from asyncio import Queue as AsyncQueue
from threading import Thread

import pyaudio
import simpleaudio as sa
import speech_recognition as sr

from gpt_service import GptService
from noun_service import noun_list
from vox_service import VoxService

gs = GptService()
vs = VoxService()


def look_for_audio_input():
    """
    ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªIFä¸€è¦§
    """
    pa = pyaudio.PyAudio()

    for i in range(pa.get_device_count()):
        print(pa.get_device_info_by_index(i))
        print()

    pa.terminate()


async def play_noun_or_fill(filler_queue: AsyncQueue):
    if not filler_queue.empty():
        fetched_index, file = filler_queue.get_nowait()
        print(f"start play voice for index {fetched_index}")
        await play_chat(file)
    else:
        await play_fill()


async def play_fill():
    fillvoices = ["ãã£ã‹ãã£ã‹", "ãã†ã‹ããƒ¼", "ãã†ã ã­ãƒ¼", "ãˆã£ã¨ã‰ãƒ¼", "ãˆã£ã¨ã­ã‡ãƒ¼", "ã†ãƒ¼ã‚“ã¨ã­"]
    wave_obj = sa.WaveObject.from_wave_file(f"fill_voice/{random.choice(fillvoices)}.wav")
    play_obj = wave_obj.play()
    play_obj.wait_done()


async def play_exit():
    exitvoices = ["ã˜ã‚ƒã‚ã­", "ã¾ãŸã­", "å…ƒæ°—ã§ã­", "ã¾ãŸè©±ãã†ã­", "ãƒã‚¤ãƒã‚¤"]
    wave_obj = sa.WaveObject.from_wave_file(f"fill_voice/{random.choice(exitvoices)}.wav")
    play_obj = wave_obj.play()
    play_obj.wait_done()


async def play_chat(file):
    wave_obj = sa.WaveObject.from_wave_file(file)
    play_obj = wave_obj.play()
    play_obj.wait_done()


def fetch_voice(q: AsyncQueue, text, index):
    result = vs.voxvoice(text, 0)
    q.put_nowait((index, result))
    print(f"Fetched voice for index {index}")


def create_noun_fill(q: AsyncQueue, text, index):
    nlist = noun_list(text)
    print(nlist)
    if len(nlist) > 0:
        noun = random.choice(nlist)
        nounfills = [f"ã‚ãƒ¼{noun}ã‹ã", f"{noun}ã­ã‡", f"{noun}ã‹ã", f"{noun}ã®è©±ã­", f"ãŠãƒ¼{noun}ã­"]
        nounfill = random.choice(nounfills)
        threading.Thread(target=fetch_voice, args=(q, nounfill, index)).start()
        print(f"Add fetch nounfill: {nounfill}")


def text_fetcher(recog: sr.Recognizer, audio: sr.AudioData, queue: AsyncQueue, threads: list[Thread], error_queue: AsyncQueue, filler_queue: AsyncQueue):
    text: str = ""
    try:
        text = recog.recognize_google(audio, language="ja-JP")
    except:
        error_queue.put_nowait("ğŸ™ğŸ™‰èãå–ã‚Šã‚¨ãƒ©ãƒ¼ğŸ™‰ğŸ™")

    if text == "":
        error_queue.put_nowait("ğŸ™ğŸ™‰èãå–ã‚Šã‚¨ãƒ©ãƒ¼ğŸ™‰ğŸ™")
        return

    print(f"user: {text}")
    if "ã˜ã‚ƒã‚ã­" in text or "ã¾ãŸã­" in text or "ãƒã‚¤ãƒã‚¤" in text:
        error_queue.put_nowait("ğŸ‘‹see you!!ğŸ‘‹")
        return

    threading.Thread(target=create_noun_fill, args=(filler_queue, text, 999)).start()

    res = gs.chat(text, prompt="ã‚ãªãŸã¯userã®å‹é”ã®ITç³»å¤§å­¦ç”Ÿã€Œã‚½ãƒ¼ã‚¿ã€ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚è‹¥ã„å¥³ã®å­ã®å£èª¿ã§ã€ä¸€äººç§°ã¯ã€Œã‚½ãƒ¼ã‚¿ã€ã§ã™ã€‚", model="gpt-3.5-turbo-0125")
    index = 0
    result = ""
    for text in res:
        print(f"Text fetched: {text}")
        result += text
        thread = threading.Thread(target=fetch_voice, args=(queue, text, index))
        threads.append(thread)
        thread.start()
        print(f"Add fetch thread for index {index}")
        index += 1
    gs.addres(result)


async def process_text(recog: sr.Recognizer, audio: sr.AudioData) -> bool:
    queue: AsyncQueue = AsyncQueue()
    filler_queue: AsyncQueue = AsyncQueue()
    error_queue: AsyncQueue = AsyncQueue()
    threads: list[Thread] = []
    played_indexes: set = set()

    # ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
    threading.Thread(target=text_fetcher, args=(recog, audio, queue, threads, error_queue, filler_queue)).start()

    # ãƒ•ã‚§ãƒƒãƒã—ãŸéŸ³å£°ã‚’é †ã«å†ç”Ÿ
    isFirst = True
    while isFirst and error_queue.empty():
        await play_noun_or_fill(filler_queue)
        while any(thread.is_alive() for thread in threads) or not queue.empty():
            if not queue.empty():
                fetched_index, file = queue.get_nowait()
                if fetched_index == len(played_indexes):
                    isFirst = False
                    print(f"start play voice for index {fetched_index}")
                    await play_chat(file)
                    played_indexes.add(fetched_index)
                else:
                    queue.put_nowait((fetched_index, file))
            await asyncio.sleep(0.1)
    while not error_queue.empty():
        e = error_queue.get_nowait()
        print(e)
        if e == "ğŸ‘‹see you!!ğŸ‘‹":
            await play_exit()
            return False
    return True


async def realtime_textise():
    # éŸ³å£°å…¥åŠ›
    is_runing = True
    while is_runing:
        r = sr.Recognizer()
        r.energy_threshold = 1000
        with sr.Microphone() as source:
            print("ç™ºè©±ã©ã†ãğŸ’¬")
            audio = r.listen(source)
        is_runing = await process_text(r, audio)


async def main():
    look_for_audio_input()
    await realtime_textise()


if __name__ == "__main__":
    asyncio.run(main())
